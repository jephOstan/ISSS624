---
title: "Geographically Weighted Regression"
editor: visual
date: 9 Dec 2022
---

case study : ***Build hedonic models for condominiums in 2015.***

## 6.1 OVERVIEW

**Geographically weighted regression (GWR)** is a spatial statistical technique that considers non-stationary variables (e.g., climate, demographic factors and physical environment characteristics). It models the local relationships between the independent variables and an outcome of interest, otherwise known as the dependent variable.

This exercise focuses on building [hedonic pricing](https://www.investopedia.com/terms/h/hedonicpricing.asp) models by using GWR methods.

-   The dependent variable is the resale prices of condominiums in 2015.

-   The independent variables are divided into either structural or location.

<br>

## 6.2 R PACKAGE REQUIRED

The following are the packages required for this exercise :

-   Building OLS and performing diagnostics tests

    -   [**olsrr**](https://olsrr.rsquaredacademy.com/)
        -   *ols.regress( ) -* [6.5.3](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#prepare-publication-quality-table-olsrr-method)

        -   *ols.vif.tol( ) -* [6.5.5](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#check-multicolinearity)

        -   *ols_plot_resid_fit( ) -* [6.5.5.1](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#test-for-non-linearity)

        -   *ols_plot_resid_hist( )* - [6.5.5.2](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#test-for-normality-assumption)

        -   *ols_test_normality( ) -* [6.5.5.2](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#test-for-normality-assumption)

-   Calibrating geographically weighted family of models

    -   [**GWmodel**](https://cran.r-project.org/web/packages/GWmodel/)
        -   *bw.gwr( )* - [6.6.1.1](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#define-stopping-rule-for-fixed-bandwith)

-   Multivariate data visualisation and analysis

    -   [**corrplot**](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html)
        -   *corrplot( )* - [6.5.2.1](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#visualising-the-relationships-of-the-independent-variables)

-   Spatial data handling

    -   **sf**
        -   *st_read( )* - [6.3.2](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#import-geospatial-data)

        -   *st_transform( )* - [6.3.2.1](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#update-crs-information)

        -   *st_crs( )* - [6.3.2.2](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#verify-transformed-projection-coordinate-system)

        -   *st_bbox( )* - [6.3.2.3](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#reveal-mpsz_svy21)

        -   *st_as_sf( )* - [6.3.4.1](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#convert-aspatial-data-frame-into-a-sf-object)

        -   *as_spatial( )* - [6.5.5.3](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#test-for-spatial-autocorrelation)

-   Attribute data handling

    -   **tidyverse**
        -   **readr**

            \-- *read_csv( )* - [6.3.3](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#import-aspatial-data)

        -   **ggplot2**

            \-- *ggplot( )* - [6.4.1](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#plot-distribution-of-selling_price)

            \-- *geom_point( ) -* [6.5.1.2](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#visualise-fit-curve-on-scatterplot)

        -   **dplyr**

            \-- *glimpse( )* - [6.3.3.1](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#examine-condo_resale)

            \-- *mutate( )* - [6.4.2.1](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#derive-new-variable-log_selling_price)

        -   **utils**

            \-- *head( ) - [6.3.3.2](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#examine-data-in-xcoord-column), [6.3.3.3](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#examine-data-in-ycoord-column)*

-   Choropleth mapping

    -   **tmap**
        -   *tmap_mode( )* - [6.4.4.1](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#set-tmap-mode-to-interactive-viewing), [6.4.4.3](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#turn-r-display-into-plot-mode)

        -   *tm_dots( )* - [6.4.4.2](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#plot-interactive-point-symbol-map)

        -   *tm_view( )* - [6.4.4.2](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#plot-interactive-point-symbol-map)

-   **ggpubr**

    -   *ggarrange( )* - [6.4.3](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#plot-multiple-histogram-distribution-of-variables),

-   gtsummary

    -   *tbl_regression( ) -* [6.5.4](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#prepare-publication-quality-table-gtsummary-method)

-   spdep

    -   *nb2listw( )* - [6.5.5.5](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#compute-distance-based-weight-matrix)

    -   *lm.morantest( ) -* [6.5.5.5](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#compute-distance-based-weight-matrix)

-   **stats**

    -   *lm( )* - [6.5.1](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#build-with-simple-linear-regression-method)

-   **Base**

    -   *summary( )* - [6.3.3.4](https://geospatial-analysis-jeph0stan.netlify.app/hands-on_ex4-6#summarise-cond_resale)

The code chunks below to install and launches these R packages into the R environment.

```{r}
pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary, utils)
```

Remarks :

[**GWmodel**](https://www.jstatsoft.org/article/view/v063i17) package provides a collection of localised spatial statistical methods, namely :

-   GW summary statistics,

-   GW principal components analysis,

-   GW discriminant analysis and various forms of GW regression;

-   Basic and robust (outlier resistant) forms.

Olsrr package is specially programmed for performing OLS regression. It provides a collection of very useful methods for building better multiple linear regression models:

-   comprehensive regression output

-   residual diagnostics

-   measures of influence

-   heteroskedasticity tests

-   collinearity diagnostics

-   model fit assessment

-   variable contribution assessment

-   variable selection procedures

<br>

## 6.3 GEOSPATIAL DATA

### 6.3.1 Acquire Data Source

Two data sets will be used in this model-building exercise, they are:

-   ***URA Master Plan subzone boundary*** :

    -   ESRI shapefile format (i.e. *MP14_SUBZONE_WEB_PL*) in svy21 projected coordinates systems

    -   Consists of URA Master Plan 2014's planning subzone boundaries.

    -   Polygon features are used to represent these geographic boundaries.

-   ***condo_resale_2015*** :

    -   CSV format, i.e. *condo_resale_2015.csv*.

### 6.3.2 Import Geospatial Data

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***st_read( )*** - sf -]{style="color:#d46e15"} to import *MP_SUBZONE_WEB_PL* shapefile.

```{r}
mpsz = st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

Remarks :

-   *mpsz* is the R simple-feature object contain the imported MP14_SUBZONE_WEB_PL shapefile.

-   The geometry type is *multipolygon*.

-   *mpsz* simple feature object does not have EPSG information.

#### 6.3.2.1 update CRS information

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***st_transform( )*** - sf -]{style="color:#d46e15"} to update the newly imported *mpsz* with the correct ESPG code, i.e. 3414.

```{r}
mpsz_svy21 <- st_transform(mpsz, 3414)
```

#### 6.3.2.2 verify transformed projection coordinate system

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***st_crs( )*** - sf -]{style="color:#d46e15"} to verify the projection metadata of the newly transformed *mpsz_svy21*.

```{r}
st_crs(mpsz_svy21)
```

Remarks :

EPSG code is indicated as *3414*.

#### 6.3.2.3 reveal *mpsz_svy21*

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***st_bbox( )*** - sf -]{style="color:#d46e15"} to return bounding of the *mpsz_svy21* simple feature set.

```{r}
st_bbox(mpsz_svy21)
```

### 6.3.3 Import Aspatial Data

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***read_csv( )*** - readr -]{style="color:#d46e15"} to import *condo_resale_2015* into R as a tibble data frame called *condo_resale*.

```{r}
condo_resale = read_csv("/jephOstan/ISSS624/data/aspatial/Condo_resale_2015.csv")
```

#### 6.3.3.1 examine *condo_resale*

[***glimpse( )*** - dplyr -]{style="color:#d46e15"} to display the data structure.

```{r}
glimpse(condo_resale)
```

#### 6.3.3.2 examine data in xcoord column

[***head( )*** - utils -]{style="color:#d46e15"} to list the value of "LONGITUDE" under *condo_resale.*

```{r}
head(condo_resale$LONGITUDE)
```

#### 6.3.3.3 examine data in ycoord column

[***head( )*** - utils -]{style="color:#d46e15"} to list the value of "LATITUDE" under *condo_resale.*

```{r}
head(condo_resale$LATITUDE)
```

#### 6.3.3.4 summarise *cond_resale*

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***summary( )*** - base -]{style="color:#d46e15"} to display the summary statistics of *cond_resale* tibble data frame.

```{r}
summary(condo_resale)
```

### 6.3.4 Wrangle Aspatial Data

#### 6.3.4.1 convert aspatial data frame into a sf object

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***st_as_sf( )*** - sf -]{style="color:#d46e15"} to convert aspatial *condo_resale* tibble data frame to a **sf** object.

```{r}
condo_resale.sf <- st_as_sf(condo_resale,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs=4326) %>%
  st_transform(crs=3414)
```

Remarks :

The coordinates from wgs84, i.e. crs : 4326 to svy21, i.e. crs : 3414.

[***head( )*** - utils -]{style="color:#d46e15"} to list the content of *condo_resale.sf* object.

```{r}
head(condo_resale.sf)
```

Remarks :

The output is in point feature data frame.

<br>

## 6.4 EXPLORATORY DATA ANALYSIS (EDA)

Use statistical graphics functions to perform EDA.

### 6.4.1 Plot Distribution of "SELLING_PRICE"

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***ggplot( )*** - ggplot2 -]{style="color:#d46e15"} to plot the distribution of "SELLING_PRICE".

```{r}
ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

Remarks :

-   The figure above reveals a right-skewed distribution. This means that more condominium units were transacted at relatively lower prices.

-   Statistically, the skewed distribution can be normalised by using log transformation.

### 6.4.2 Plot "LOG_SELLING_PRICE"

#### 6.4.2.1 derive new variable :: "LOG_SELLING_PRICE"

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***mutate( )*** - dplyr -]{style="color:#d46e15"} to derive a new variable - "LOG_SELLING_PRICE" by using a log transformation on the variable "SELLING_PRICE".

```{r}
condo_resale.sf <- condo_resale.sf %>%
  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))
```

#### 6.4.2.2 plot "LOG_SELLING_PRICE"

```{r}
ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

Remarks :

Notice the distribution is relatively less skewed after the transformation.

### 6.4.3 Plot Multiple Histogram :: Distribution of Variables

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***ggarrange( )*** - ggpubr -]{style="color:#d46e15"} to draw multiple small histograms (also known as trellis plot) consisting of 12 histograms. Then, `ggarrange()` is used to organise these histograms into 3 columns by 4 rows of multiple small plots.

```{r}
AREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + 
  geom_histogram(bins=20, color="black", fill="light blue")

AGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + 
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_URA_GROWTH_AREA`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, 
          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,
          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  
          ncol = 3, nrow = 4)
```

### 6.4.4 Plot Statistical Point Map

Reveal the geospatial distribution condominium resale prices in Singapore.

#### 6.4.4.1 set tmap mode to interactive viewing

```{r}
tmap_mode("view")
```

#### 6.4.4.2 plot interactive point symbol map

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***tm_dots( )*** - tmap -]{style="color:#d46e15"} to create an interactive point symbol map.

[***tm_view( )*** - tmap -]{style="color:#d46e15"} use set.zoom.limits function to set the minimum and maximum zoom level to 11 and 14 respectively.

```{r}
tm_shape(mpsz_svy21)+
  tmap_options(check.and.fix = TRUE)+
  tm_polygons()+
tm_shape(condo_resale.sf) +  
  tm_dots(col = "SELLING_PRICE",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

#### 6.4.4.3 turn R display into "plot" mode

```{r}
tmap_mode("plot")
```

<br>

## 6.5 HEDONIC PRICING MODELLING

Build hedonic pricing models for condominium resale units using [`lm()`](https://www.rdocumentation.org/packages/stats/versions/3.5.2/topics/lm) of R base.

### 6.5.1 Build with Simple Linear Regression Method

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***lm( )*** - stats -]{style="color:#d46e15"} to build a simple linear regression model by using :

-   "SELLING_PRICE" as the dependent variable.

-   "AREA_SQM" as the independent variable.

```{r}
condo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)
```

Remarks :

-   lm( ) returns an object of class "lm" or for multiple responses of class c("mlm", "lm").

-   The functions `summary()` and `anova()` can be used to obtain and print a summary and analysis of variance table of the results.

-   The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by `lm`.

#### 6.5.1.1 summarise *condo.slr*

```{r}
summary(condo.slr)
```

Remarks :

-   The output report reveals that the "SELLING_PRICE" can be explained by using the formula :

    \*y = - 258121.1 + 14719 x1\*

-   The R-squared of 0.4518 reveals that the simple regression model can explain about 45% of the resale prices.

-   The p-value is smaller than 0.0001, rejecting the null hypothesis. Therewith, the simple linear regression model is inferred to be a good estimator for "SELLING_PRICE".

-   The **Coefficients :** both p-values for the "Intercept" and "ARA_SQM" are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. Thus, B0 and B1 are inferred to be good parameter estimates.

#### 6.5.1.2 visualise fit curve on scatterplot

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***geom_point( )*** - ggplot2 -]{style="color:#d46e15"} to visualise the best fit curve on a scatter plot.

```{r}
ggplot(data=condo_resale.sf,  
       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +
  geom_point() +
  geom_smooth(method = lm)
```

Remarks :

There are a few statistical outliers with relatively high selling prices.

### 6.5.2 Multiple Linear Regression Method

-   Before building a multiple regression model, it is important to ensure that the independent variables used are not highly correlated to each other.

-   **Multicollinearity** happens when highly correlated independent variables are used in building a regression model, and the quality of the model will be compromised.

-   Correlation matrix is commonly used to visualise the relationships between the independent variables.

-   Besides the `pairs()` of R, many packages support the display of a correlation matrix.

#### 6.5.2.1 Visualising the relationships of the independent variables

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***corrplot( )*** - corrplot -]{style="color:#d46e15"} to plot a scatter plot matrix of the relationship between the independent variables in *condo_resale* data.frame.

```{r}
corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.55, method = "number", type = "upper")
```

Remarks :

-   Avoid condo_resale_sf as the table consists of "geometry" at the end.

<!-- -->

-   Matrix reorder is very important for mining the hiden structure and patter in the matrix.

-   There are four methods in corrplot (parameter order), named "AOE", "FPC", "hclust", "alphabet".

-   AOE = orders the variables by using the *angular order of the eigenvectors* method suggested by [Michael Friendly](https://www.datavis.ca/papers/corrgram.pdf).

-   From the scatterplot matrix, it is clear that ***Freehold*** is highly correlated to ***LEASE_99YEAR***. In view of this, ***LEASE_99YEAR*** is excluded in the subsequent model building.

#### 6.5.2.2 build hedonic pricing model

```{r}
condo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + 
                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + 
                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + 
                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + 
                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                data=condo_resale.sf)
summary(condo.mlr)
```

Remarks :

Not all the independent variables are statistically significant. The model will be calibrated by removing those variables which are not statistically significant.

### 6.5.3 Prepare Publication Quality Table :: olsrr method

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***ols_regress( )*** - olsrr -]{style="color:#d46e15"} to calibrate the model.

```{r}
condo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + 
                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + 
                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,
                 data=condo_resale.sf)
ols_regress(condo.mlr1)
```

Remarks :

-   ANOVA Significant value is 0.0000, hence allow to reject null hypothesis.

-   "AGE" is inverse relationship with the price. E.g. 1 unit increase of the "AGE", the price will reduce by -\$24687.739.

-   "FREEHOLD" is True, the price will increase by \$350599.812.

### 6.5.4 Prepare Publication Quality Table :: gtsummary method

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***tbl_regression( )*** - gtsummary -]{style="color:#d46e15"} to create a well formatted regression report.

```{r}
tbl_regression(condo.mlr1, intercept = TRUE)
```

Remarks :

With gtsummary package, model statistics can be included in the report by either appending them to the report table by using [`add_glance_table()`](https://www.danieldsjoberg.com/gtsummary/reference/add_glance.html) or adding as a table source note by using [`add_glance_source_note()`](https://www.danieldsjoberg.com/gtsummary/reference/add_glance.html) as shown in the code chunk below.

```{r}
tbl_regression(condo.mlr1, 
               intercept = TRUE) %>% 
  add_glance_source_note(
    label = list(sigma ~ "\U03C3"),
    include = c(r.squared, adj.r.squared, 
                AIC, statistic,
                p.value, sigma))
```

### 6.5.5 Check Multicolinearity

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***ols_vif_tol( )*** - olsrr -]{style="color:#d46e15"} to test if there are sign of multicollinearity.

```{r}
ols_vif_tol(condo.mlr1)
```

Remarks :

Since the VIF of the independent variables is less than 10, can safely conclude that there is no sign of multicollinearity among the independent variables.

#### 6.5.5.1 test for Non-Linearity

In multiple linear regression, it is important to test the assumption that linearity and additivity of the relationship between dependent and independent variables.

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***ols_plot_resid_fit( )*** - olsrr -]{style="color:#d46e15"} to perform linearity assumption test.

```{r}
ols_plot_resid_fit(condo.mlr1)
```

Remarks :

The figure above reveals that most of the data poitns are scattered around the 0 line, hence can safely conclude that the relationships between the dependent variable and independent variables are linear.

#### 6.5.5.2 test for Normality Assumption

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***ols_plot_resid_hist( )*** - olsrr -]{style="color:#d46e15"} to perform normality assumption test.

```{r}
ols_plot_resid_hist(condo.mlr1)
```

Remarks :

The figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.

[***ols_test_normality( )*** - olsrr -]{style="color:#d46e15"} to use formal statistical test methods.

```{r}
ols_test_normality(condo.mlr1)
```

Remarks :

The summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence, reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.

#### 6.5.5.3 test for Spatial Autocorrelation

-   The hedonic model is using geographically referenced attributes, hence it is also important to visual the residual of the hedonic pricing model.

-   In order to perform spatial autocorrelation test, *condo_resale.sf* need to be converted from sf data frame into a **SpatialPointsDataFrame**.

-   First, export the residual of the hedonic pricing model and save it as a data frame.

```{r}
mlr.output <- as.data.frame(condo.mlr1$residuals)
```

Next, join the newly created data frame with *condo_resale.sf* object.

```{r}
condo_resale.res.sf <- cbind(condo_resale.sf, 
                        condo.mlr1$residuals) %>%
rename(`MLR_RES` = `condo.mlr1.residuals`)
```

Next, convert *condo_resale.res.sf* from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***as_spatial( )*** - sf -]{style="color:#d46e15"} to perform the data conversion process.

```{r}
condo_resale.sp <- as_Spatial(condo_resale.res.sf)
condo_resale.sp
```

#### 6.5.5.4 create interactive point symbol map

Use **tmap** package to display the distribution of the residuals on an interactive map.

```{r}
tmap_mode("view")
```

```{r}
tm_shape(mpsz_svy21)+
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.4) +
tm_shape(condo_resale.res.sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

```{r}
tmap_mode("plot")
```

Remarks :

The figure above reveal that there is sign of spatial autocorrelation.

To proof the observation is true, the Moran's I test will be performed.

#### 6.5.5.5 compute distance-based weight matrix

```{r}
nb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)
summary(nb)
```

[***nb2listw( )*** - spdep -]{style="color:#d46e15"} to convert the output neighbours lists, i.e. nb into a spatial weights.

```{r}
nb_lw <- nb2listw(nb, style = 'W')
summary(nb_lw)
```

[***lm.morantest( )*** - spdep -]{style="color:#d46e15"} to perform Moran's I test for residual spatial autocorrelation

```{r}
lm.morantest(condo.mlr1, nb_lw)
```

Remarks :

-   The Global Moran's I test for residual spatial autocorrelation shows that it's p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, reject the null hypothesis that the residuals are randomly distributed.

-   Since the Observed Global Moran I = 0.1424418 which is greater than 0, the residuals are inferred to resemble cluster distribution.

## 6.6 HEDONIC PRICING MODELLING :: GWmodel

Build hedonic pricing modelling using both the fixed and adaptive bandwidth schemes.

### 6.6.1 Build Fixed Bandwidth GWR Model

#### 6.6.1.1 define stopping rule for fixed bandwith

[Usage of the code chunk below]{style="color:#a39f9d"} :

[***bw.gwr( )*** - GWmodel -]{style="color:#d46e15"} to determine the optimal fixed bandwidth to use in the model.

***adaptive*** argument is set to **FALSE** = compute the fixed bandwidth.

Two (2) approaches to determine the stopping rule :

-   CV cross-validation approach

-   AIC corrected (AICc) approach

For 6.6.1.1, the stopping rule is defined using ***AIC corrected*** ***approach***.

```{r}
bw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + 
                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                     FAMILY_FRIENDLY + FREEHOLD, 
                   data=condo_resale.sp, 
                   approach="CV", 
                   kernel="gaussian", 
                   adaptive=FALSE, 
                   longlat=FALSE)
```

Remarks :

The result shows that the recommended bandwidth is 971.3405 metres.

#### 6.6.1.2 calibrate gwr model

Calibrate the gwr model using fixed bandwidth and gaussian kernel.

```{r}
gwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + 
                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                         FAMILY_FRIENDLY + FREEHOLD, 
                       data=condo_resale.sp, 
                       bw=bw.fixed, 
                       kernel = 'gaussian', 
                       longlat = FALSE)

gwr.fixed
```

Remarks :

The report shows that the adjusted r-square of the gwr is 0.8430 which is significantly better than the globel multiple linear regression model of 0.6472.

### 6.6.2 Build Adaptive Bandwidth GWR Model

Calibrate the gwr-absed hedonic pricing model by using adaptive bandwidth approach.

#### 6.6.2.1 compute the adaptive bandwidth

[Usage of the code chunk below]{style="color:#a39f9d"} : to determine the recommended data point to use.

-   The code chunk used look very similar to the one used to compute the fixed bandwidth except the ***adaptive*** argument has changed to **TRUE**.

```{r}
bw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + 
                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + 
                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + 
                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                      data=condo_resale.sp, 
                      approach="CV", 
                      kernel="gaussian", 
                      adaptive=TRUE, 
                      longlat=FALSE)
```

Remarks :

The result shows that the 30 is the recommended data points to be used.

#### 6.6.2.2 construct adaptive bandwidth gwr model

[Usage of the code chunk below]{style="color:#a39f9d"} : calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel.

```{r}
gwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + 
                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + 
                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                          data=condo_resale.sp, bw=bw.adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE, 
                          longlat = FALSE)

gwr.adaptive
```

Remarks :

The report shows that the adjusted r-square of the gwr is 0.8561 which is significantly better than the globel multiple linear regression model of 0.6472.

"longlat" is set to FALSE when the data is in projected coordinate system. Set to TRUE if in degree.

### 6.6.3 Visualise GWR Output

In addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:

-   Condition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.

-   Local R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.

-   Predicted : these are the estimated (or fitted) y values 3. computed by GWR.

-   Residuals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produced by using these values.

-   Coefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates is higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.

They are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its "data" slot in an object called **SDF** of the output list.

### 6.6.4 Convert SDF into *sf* data.frame

[Usage of the code chunk below]{style="color:#a39f9d"} : to covert SDF into **sf** data.frame.

```{r}
condo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%
  st_transform(crs=3414)
```

```{r}
condo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)
condo_resale.sf.adaptive.svy21  
```

```{r}
gwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)
condo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))
```

```{r}
glimpse(condo_resale.sf.adaptive)
```

```{r}
summary(gwr.adaptive$SDF$yhat)
```

### 6.6.5 Visualise Local R2

[Usage of the code chunk below]{style="color:#a39f9d"} : to create an interactive point symbol map.

```{r}
tmap_mode("view")
tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))
```

```{r}
tmap_mode("plot")
```

#### 6.6.5.1 visualise coefficient estimates

```{r}
tmap_mode("view")
AREA_SQM_SE <- tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_SE",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

AREA_SQM_TV <- tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_TV",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

tmap_arrange(AREA_SQM_SE, AREA_SQM_TV, 
             asp=1, ncol=2,
             sync = TRUE)
```

```{r}
tmap_mode("plot")
```

#### 6.6.5.2 plot with URA Planning Region

```{r}
tm_shape(mpsz_svy21[mpsz_svy21$REGION_N=="CENTRAL REGION", ])+
  tm_polygons()+
tm_shape(condo_resale.sf.adaptive) + 
  tm_bubbles(col = "Local_R2",
           size = 0.15,
           border.col = "gray60",
           border.lwd = 1)
```

## 6.7 REFERENCE

-   Gollini I, Lu B, Charlton M, Brunsdon C, Harris P (2015) "GWmodel: an R Package for exploring Spatial Heterogeneity using Geographically Weighted Models". *Journal of Statistical Software*, 63(17):1-50, http://www.jstatsoft.org/v63/i17/

-   Lu B, Harris P, Charlton M, Brunsdon C (2014) "The GWmodel R Package: further topics for exploring Spatial Heterogeneity using GeographicallyWeighted Models". *Geo-spatial Information Science* 17(2): 85-101, http://www.tandfonline.com/doi/abs/10.1080/1009502.2014.917453

-   r4gdsa.netlify.app. https://r4gdsa.netlify.app/chap06.html#hedonic-pricing-modelling-in-r
