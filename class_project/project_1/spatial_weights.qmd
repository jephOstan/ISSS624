---
title: "Geospatial Analytics for Social Good"
editor: visual
date: 29 Nov 2022
---

## 1. OVERVIEW

The main aim of this project is to use the water point related data from rural areas at the water point or small water scheme level available from the WPdx Data Repository to explore the applicable geospatial analysis tools in water resources management for Nigeria.

### 1.1 Problem Statement

To address the issue of providing clean and sustainable water supply to the rural community.

### 1.2 Objectives

Apply appropriate **global and local measures of spatial Association techniques** to reveals the spatial patterns of **Not Functional water points**.

### 1.3 Scope of Works

Below are the list of tasks to be completed :

-   Import the shapefile into R and save it in a simple feature data frame format with appropriate **sf** method.

    note : Nigeria (NGA) has 3 Projected Coordinate Systems, EPSG: 26391, 26392, and 26303.

-   Derive the proportion of functional and non-functional water point at LGA level with appropriate **tidyr** and **dplyr** methods,

-   Combine the geospatial and aspatial data frame into simple feature data frame.

-   Performe outliers / clusters analysis by using appropriate local measures of spatial association methods.

-   Perform hotspot areas analysis by using appropriate local measures of spatial association methods.

-   Plot 2 main types of maps below :

    1.  **Thematic Mapping**

        Plot maps to show the spatial distribution of functional and non-functional water point rate at LGA level by using appropriate thematic mapping technique provided by tmap package.

    2.  **Analytical Mapping**

        Plot hotspot areas and outliers / clusters maps of functional and non-functional water point rate at LGA level by using appropriate thematic mapping technique provided by tmap package.

<br>

## 2. R PACKAGE REQUIRED

Following are the packages require for this exercise :

-   pacman package : to install and load the following R packages into R environment.

-   **sf** package :

    -   *st_read( )* = import and save the shapefiles into simple feature data table.
    -   [*st_geometry( )*](https://r-spatial.github.io/sf/reference/st_geometry.html) = get geometry from an sf object.
    -   [*st_centroid( )*](https://r-spatial.github.io/sf/reference/geos_unary.html) - takes a polygon or multipolygon and returns the geometric center of the bounding box of the polygon or multipolygon as a point.

-   **tidyverse** package :

    -   [**dplyr**](https://dplyr.tidyverse.org/):

        -   *filter( )* - extract water point records of Nigeria.
        -   [*glimpse( )*](https://dplyr.tidyverse.org/reference/glimpse.html) *-* list all columns in a data frame.
        -   [*mutate( )*](https://dplyr.tidyverse.org/reference/mutate.html) *-* edit variables' values.

    -   [**readr**](https://readr.tidyverse.org/) :

        -   [*write_rds( )*](https://readr.tidyverse.org/reference/read_rds.html) - save the extracted sf data table into an output file in rds data format.

    -   **stringr** :

        -   [*str_replace( )*](https://stringr.tidyverse.org/reference/str_replace.html) - replace some characters with some other characters in a string.

-   **tmap** package :

    -   *qtm( )* - to plot quick thematic map.

    -   [*tm_shape( )*](https://www.rdocumentation.org/packages/tmap/versions/3.3-3/topics/tm_shape) - specify the shape object.

-   **spdep** package :

    -   [*poly2nb( )*](https://r-spatial.github.io/spdep/reference/poly2nb.html) *-* compute contiguity weight matrices for the study area.

    -   [*nb2listw( )*](https://www.rdocumentation.org/packages/spdep/versions/1.2-7/topics/nb2listw) *-* supplements a neighbours list with spatial weights for the chosen coding scheme.

    -   [*moran.test( )*](https://r-spatial.github.io/spdep/reference/moran.test.html) - for spatial autocorrelation using a spatial weights matrix in weights list form.

    -   [*moran.mc( )*](https://r-spatial.github.io/spdep/reference/moran.mc.html) *-* for permutation test with Moran's I statistic.

    -   [*geary.test( )*](https://r-spatial.github.io/spdep/reference/geary.test.html) *-* for spatial autocorrelation using a spatial weights matrix in weights list form.

    -   [*geary.mc( )*](https://r-spatial.github.io/spdep/reference/geary.mc.html) *-* for permutation test with Geary's C statistic.

    -   [*sp.correlogram(*](https://r-spatial.github.io/spdep/reference/sp.correlogram.html) *) - s*patial correlograms for Moran's I and the autocorrelation coefficient.

    -   [*localmoran( )*](https://r-spatial.github.io/spdep/reference/localmoran.html) *-* to calculate local spatial statistics for each zone based on the spatial weights object used.

    -   [*moran.plot( )*](https://r-spatial.github.io/spdep/reference/moran.plot.html) *-* plot of spatial data against its spatially lagged values.

    -   [*knearneigh ( )*](https://r-spatial.github.io/spdep/reference/knearneigh.html) - return matrix with the indices of points belonging to the set of the k nearest neighbours of each other.

    -   [*knn2nb( )*](https://r-spatial.github.io/spdep/reference/knn2nb.html) - convert knn object to a neighbours list of class nb.

    -   [*nbdist( )*](https://www.rdocumentation.org/packages/spdep/versions/1.2-4/topics/nbdists) - return the length of neighbour relationship edges.

    -   [*dnearneigh( )*](https://r-spatial.github.io/spdep/reference/dnearneigh.html) - derive distance-based weight matrices.

    -   [*localG( )*](https://www.rdocumentation.org/packages/spdep/versions/1.1-3/topics/localG) - calculate local spatial statistic G for each zone based on the spatial weights object used.

-   **funModeling** package :

    -   [*freq( )*](https://www.rdocumentation.org/packages/funModeling/versions/1.9.4/topics/freq) = retrieves the frequency and percentage for input.

-   janitor package :

    -   [*get_dupes( )*](https://www.rdocumentation.org/packages/janitor/versions/2.1.0/topics/get_dupes) = search duplicated records during data wrangling.

### 2.1 Load R Packages into R Environment

Use the code chunk below.

```{r}
pacman::p_load(sf, tidyverse, tmap, spdep, funModeling, janitor, maps)
```

<br>

## 3. GEOSPATIAL DATA

### 3.1 Acquire Data Source

-   **Aspatial Data**

    1.  Download the Nigeria data set in shapefile format via [Access WPdx+ Global Data Repository](https://data.waterpointdata.org/dataset/Water-Point-Data-Exchange-Plus-WPDx-/eqje-vguj/data) from [WPdx Global Data Repositories](https://www.waterpointdata.org/access-data/).
    2.  Rename the title of the data set to "***geo_export***".

-   **Geospatial Data**

    1.  Download the Nigeria geoBoundaries data set at ADM2 level from [geoBoundaries.org](https://www.geoboundaries.org/index.html#getdata) or the [Humanitarian Data Exchange portal](https://data.humdata.org/).
    2.  Rename the title of the data set to "***nga_admbnda_adm2_osgof_20190417***"

### 3.2 Import Aspatial Data - Water Point Shapefile

Use the code chunk below.

Note :

-   *st_read( )* to import geo_export data set.

-   *#\| eval: false* to display the code chunks without the output.

```{r}
#| eval: false
wp <- st_read(dsn = "/jephOstan/ISSS624/class_project/project_1/data/geodata",
              layer = "geo_export",
              crs = 4326) %>%
  filter(clean_coun == "Nigeria")
```

#### 3.2.1 Review Imported Aspatial Shapefile

#### \-- retrieve geometry list-column

Use the code chunk below.

Note :

*st_geometry( )* to get the geometry summary of a class data.frame or sf object.

```{r}
#| eval: false
st_geometry(wp)
```

#### \-- identify associated attribute

Use the code chunk below.

Note :

*glimpse( )* to swtich columns to rows, features to columns.

```{r}
#| eval: false
glimpse(wp)
```

``` {.column-margin style="color: #9e6024; border-width: 3px;   border-style: solid;   border-color: #ebbd8f;"}

Avoid performing transformation 
if going to use st_intersects() 
in geoprocessing stage. This is 
because st_intersects() only 
works correctly if the geospatial 
data are in geographic coordinate 
system (i.e. wgs84)
```

#### 3.2.2 Write "wp" in RDS Format

Use the code chunk below.

Notes :

-   *write_rds( )* to save the extracted sf data table, i.e. "wp" into an output file in rds data format.

The output file is called "*wp_nga.rds"* and it is saved in *geodata* sub-folder."

```{r}
#| eval: false
write_rds(wp, "/jephOstan/ISSS624/class_project/project_1/data/geodata/wp_nga.rds")
```

### 3.3 Import Geospatial Data - Nigeria LGA Boundary Data

Use the code chunk below.

Notes :

-   *st_read( )* to import geo_export data set.

```{r}
#| eval: false
nga <- st_read(dsn = "/jephOstan/ISSS624/class_project/project_1/data/geodata",
               layer = "nga_admbnda_adm2_osgof_20190417",
               crs = 4326)
```

#### 3.3.1 Review Imported Geospatial Shapefile

#### \-- retrieve geometry list-column

Use the code chunk below.

Note :

*st_geometry( )* to get the geometry summary of a class data.frame or sf object.

```{r}
#| eval: false
st_geometry(nga)
```

#### \-- identify associated attribute

Use the code chunk below.

Note :

*glimpse( )* to swtich columns to rows, features to columns.

```{r}
#| eval: false
glimpse(nga)
```

### 3.4 Data Wrangling and Exploratory Data Analysis (EDA)

#### 3.4.1 Recode NA Values into String

Use the code chunk below.

Note :

*glimpse( )* to recode all the *NA* values in *status_cle* field into *Unknown*.

```{r}
#| eval: false
wp_nga <- read_rds("/jephOstan/ISSS624/class_project/project_1/data/geodata/wp_nga.rds") %>%
  mutate(status_cle = replace_na(status_cle, "Unknown"))
```

#### 3.4.2 Search Duplicate Rows

Use the code chunk below.

Note :

*get_dupes( )* to review rows that have duplicates. Specify the data.frame and the variable combination to search for duplicates and get back the duplicated rows.

Assumption :

For the same value of clean_adm2, each observation has unique pair of lat_deg and lon_deg.

```{r}
#| eval: false
duplicates <- wp_nga %>% 
                janitor::get_dupes(clean_adm2,lat_deg,lon_deg)

duplicates
```

<br>

#### 3.4.3 Exploratory Data Analysis

Before proceed to analysis stage, sense the data with EDA.

Use the code chunk below.

Note :

*freq( )* to display the distribution of *status_cle* field in *wp_nga*.

```{r}
#| eval: false
freq(data=wp_nga, 
     input = 'status_cle')
```

Remarks :

During the first round of EDA, noticed there are 2 values of "Non-functional due to dry season".

<br>

Use mutate( ) with str_replace to combine both values, thereafter update the dataset.

```{r}
#| eval: false
wp_nga <- wp_nga %>%
  mutate(status_cle = str_replace(status_cle,"Non functional due to dry season"  ,"Non-Functional due to dry season"))
```

#### 3.4.4 Explore Variables and Values for "Non-Functional"

Use the code chunk below.

Note :

*filter( )* to get the data tables based on values associated with "Non-Functional" under "status_clean" variable.

#### \-- retrieve based on "Non-Functional"

```{r}
#| eval: false
wp_nfc <- filter(wp_nga, status_cle == "Non-Functional")
wp_nfc
```

#### \-- retrieve based on "Non-Functional due to dry season"

```{r}
#| eval: false
wp_nfcD <- filter(wp_nga, status_cle == "Non-Functional due to dry season")
wp_nfcD
```

According to the variables' definition from the waterpointdata.org :

-   **usage_cap** (usage_capacity) = recommended maximum users per water point :

    -   1,000 people per mechanised well
    -   500 people per hand pump / undefined shallow well (all hand pumps)
    -   400 people per open hand well (rope & bucket)
    -   250 people per tap (tapstand, kiosk, rainwater catchment)

-   **local_popu** (local_population_1km) = number of people living within a 1km radius of the water point.

-   **served_pop** (water_point_population) = number of people currently or potentially served by a specific water point.

    -   For non-functional water points, this number represents users who would gain access if the point was functional.

-   **pressure** (pressure_score) = the pressure score ( 0 - 100% ) is calculated based on the ratio of the number of people assigned to that water point over the theoretical maximum population which can be served based on the technology.

    -   If a point is serving less than the recommended maximum, the pressure score will be less than 100% (i.e., 250/500 = 0.5).
    -   If serving more than the recommended maximum, the pressure score will be over 100% (i.e. 750/500 = 150%).

-   **crucialness** (crucialness_score) = the crucialness score ( 0 - 100% ) is the ratio is likely current users to the total local population within a 1km radius of the water point.

    -   For non-functional water points, the crucialness score shows how important the water point would be if it were to be rehabilitated.

#### 3.4.5 Plot Preliminary Visualisation for Non-Functional Water Points

```{r}
#| eval: false
plot(wp_nfc["crucialnes"])
```

Remarks :

1.  Visually, noticeable of clusters.
    -   This suggests new installation or more resources required to upgrade or rehabilitate the existing facility in order to support population for those light.

#### 3.4.6 Plot Preliminary Visualisation for Non-Functional due to Dry Season Water Points

```{r}
#| eval: false
plot(wp_nfcD["crucialnes"])
```

#### 3.4.7 Plot Preliminary Visualisation for Distribution of Urban & Non-Urban

```{r}
#| eval: false
plot(wp_nga["is_urban"])
```

<br>

### 3.5 Water Point Data Extraction

#### 3.5.1 Extract Non-functional Water Point

Use the code chunk below.

Note :

*filter( )* to get water points that associated to the variation of "Non-Functional".

```{r}
#| eval: false
wpt_nonfunctional <- wp_nga %>%
  filter(status_cle %in%
           c("Abandoned/Decommissioned", 
             "Abandoned",
             "Non-Functional",
             "Non-Functional due to dry season"))
```

```{r}
#| eval: false
freq(data=wpt_nonfunctional, 
     input = 'status_cle')
```

#### 3.5.2 Extract Functional Water Point

Use the code chunk below.

Note :

*filter( )* to get water points that associated to the variation of "Functional".

```{r}
#| eval: false
wpt_functional <- wp_nga %>%
  filter(status_cle %in%
           c("Functional", 
             "Functional but not in use",
             "Functional but needs repair"))
```

```{r}
#| eval: false
freq(data=wpt_functional, 
     input = 'status_cle')
```

#### 3.5.3 Extract Unknown Water Point

Use the code chunk below.

Note :

*filter( )* to get water points that associated to the variation of "Unknown".

```{r}
#| eval: false
wpt_unknown <- wp_nga %>%
  filter(status_cle == "Unknown")
```

#### 3.5.4 Perform Point-In-Polygon Count

Use the code chunk below.

```{r}
#| eval: false
nga_wp <- nga %>% 
  mutate(`total_wpt` = lengths(
    st_intersects(nga, wp_nga))) %>%
  mutate(`wpt_functional` = lengths(
    st_intersects(nga, wpt_functional))) %>%
  mutate(`wpt_nonFunctional` = lengths(
    st_intersects(nga, wpt_nonfunctional))) %>%
  mutate(`wpt_unknown` = lengths(
    st_intersects(nga, wpt_unknown)))
```

#### 3.5.5 Add New Variables

Use the code chunk below.

Note :

*mutate( )* to add "pct_functional" and "pct_non-functional".

*write_rds( )* to save the sf data table into rds format.

```{r}
#| eval: false
nga_wp <- nga_wp %>%
  mutate(pct_functional = `wpt_functional`/`total_wpt`) %>%
  mutate(`pct_non-functional` = `wpt_nonFunctional`/`total_wpt`)
```

```{r}
#| eval: false
write_rds(nga_wp, "/jephOstan/ISSS624/class_project/project_1/data/geodata/nga_wp.rds")
```

#### 3.5.6 Spatial Distribution of Water Points Visualisation

```{r}
nga_wp <- read_rds("/jephOstan/ISSS624/class_project/project_1/data/geodata/nga_wp.rds")
```

```{r}
total <- qtm(nga_wp, "total_wpt") + 
  tm_layout(legend.height = 0.3, legend.width = 0.3)

wp_functional <- qtm(nga_wp, "wpt_functional") +
  tm_layout(legend.height = 0.3, legend.width = 0.3)

wp_nonfunctional <- qtm(nga_wp, "wpt_nonFunctional") + 
  tm_layout(legend.height = 0.3, legend.width = 0.3)

unknown <- qtm(nga_wp, "wpt_unknown") + tm_layout(legend.height = 0.3, legend.width = 0.3)

tmap_arrange(total, wp_functional, wp_nonfunctional, unknown, asp=1.5, ncol=2)
```

### 3.6 Exploratory Spatial Data Analysis

Determine autocorrelation for non-functional water points data.

#### 3.6.1 Contiguity Weight Matrices (CWM)

Compute Contiguity Weight Matrices (CWM) first before compute the Global Spatial Autocorrelation statistics.

#### 3.6.1.1 compute Contiguity Weight Matrices

Determine the adjacency with 2 methods, Queen and Rook methods and derive W~q~ and W~r~ from the methods respectively.

#### \-- compute QUEEN contiguity based neighbours

Use the code chunk below.

Note :

*poly2nb( )* to return a list of first order neighbours based on Queen criteria.

```{r}
#| eval: false
nga_wpQ <- poly2nb(nga_wp, queen=TRUE)
summary(nga_wpQ)
```

#### \-- compute ROOK contiguity based neighbours

Use the code chunk below.

Note :

*poly2nb( )* to return a list of first order neighbours based on Queen criteria.

```{r}
#| eval: false
nga_wpR <- poly2nb(nga_wp, queen = FALSE)
summary(nga_wpR)
```

#### \-- Compare Queen and Rook Contiguity Matrices

|                                       | W~q~            | W~r~            |
|---------------------------------------|-----------------|-----------------|
| Number of regions without links       | 1 link (#86)    | 1 link (#86)    |
| Number of regions with the most links | 14 links (#508) | 14 links (#508) |
| Number of regions with 1 link         | #138, #560      | #138, #560      |
| Average number of links per region    | 5.736           | 5.711           |

Both methods have relatively similar performance, only have 1 region without links.

<br>

#### 3.6.1.2 compute Distance-Based Neighbours

Identify neighbours of region points by Euclidean distance with a distance band.

#### \-- compute "coords"

Use the code chunk below.

Note :

*cbind( )* to combine both longitude and latitude

```{r}
#| eval: false
longitude <- wp_nga$lon_deg
latitude <- wp_nga$lat_deg
coords <- cbind(longitude, latitude)
head(coords)
```

#### \-- determine the upper limit for distance band

Use the code chunk below.

Note :

*knn2nb( )* to convert knn objects that returned by *knearneigh( )* into a neighbours list of class nb.

*nbdist( )* to return the length of neighbour relationship edges.

*unlist( )* to remove the list structure of the returned object.

```{r}
k3 <- knn2nb(knearneigh(coords,k = 3))
k3dists <- unlist(nbdists(k3, coords, longlat = TRUE))
summary(k3dists)
```

```{r}
upper_threshold3 <- unlist(nbdists(k3, coords, longlat = TRUE))
```

Remarks :

The largest first nearest neighbour distance is 39.085 km, using this as the upper threshold gives certainty that all units will have at least one neighbour.

```{r}
k5 <- knn2nb(knearneigh(coords,k = 5))
k5dists <- unlist(nbdists(k5, coords, longlat = TRUE))
summary(k5dists)
upper_threshold5 <- unlist(nbdists(k5, coords, longlat = TRUE))
```

```{r}
k6 <- knn2nb(knearneigh(coords,k = 6))
k6dists <- unlist(nbdists(k6, coords, longlat = TRUE))
summary(k6dists)
upper_threshold6 <- unlist(nbdists(k6, coords, longlat = TRUE))
```

```{r}
k8 <- knn2nb(knearneigh(coords,k = 8))
k8dists <- unlist(nbdists(k8, coords, longlat = TRUE))
summary(k8dists)
upper_threshold8 <- unlist(nbdists(k8, coords, longlat = TRUE))
```

#### \-- compute fixed distance weight matrix

Use the code chunk below.

Note :

*dnearneigh( )* to derive distance-based weight matrices.

```{r}
#| eval: false
wm_d39 <- dnearneigh(coords, 0, upper_threshold3, longlat = TRUE)
wm_d39
```

```{r}
#| eval: false
wm_d40 <- dnearneigh(coords, 0, upper_threshold5, longlat = TRUE)
wm_d40
```

```{r}
#| eval: false
wm_d43 <- dnearneigh(coords, 0, upper_threshold6, longlat = TRUE)
wm_d43
```

```{r}
#| eval: false
wm_d45 <- dnearneigh(coords, 0, upper_threshold8, longlat = TRUE)
wm_d45
```

#### 3.6.1.3 list all fixed distance weight matrix

```{r}
#| eval: false
str(wm_d43)
```

#### \-- plot Fixed Distance Weight Matrix

```{r}
#| eval: false
plot(nga_wp$geometry, border="lightgrey")
plot(wm_d43, coords, add = TRUE)
plot(k1, coords, add = TRUE, col = "red", length = 0.08)
```

|                                          | W~d=3~   | W~d=5~   | W~d=6~   | W~d=8~   |
|------------------------------------------|----------|----------|----------|----------|
| Largest first nearest neighbour distance | 39.08489 | 40.08029 | 42.28107 | 44.87575 |

#### 3.6.1.4 compute Adaptive Distance Weight Matrix

```{r}
knn6 <- knn2nb(knearneigh(coords, k=6))
knn6
```

#### \-- plot Adaptive Distance Weight Matrix

```{r}
plot(nga_wp$geometry, border="lightgrey")
plot(knn6, coords, pch = 5, cex = 0.3, add = TRUE, col = "red")
```

#### 3.6.2 Global Spatial Autocorrelation (GSA)

#### 3.6.2.1 compute row-standardised weights matrix

Use the code chunk below.

Note :

*nb2listw( )* to assign weights to each neighboring polygon. Each neighboring polygon will be assigned equal weight by explore with different input for style i.e. "W", "B" and "C".

```{r}
wm_q <- poly2nb(nga_wp, queen = TRUE)
wm_q
```

```{r}
set.ZeroPolicyOption(TRUE)

ngaWp_rswmQW <- nb2listw(wm_q, style = "W", zero.policy = TRUE)
ngaWp_rswmQW
```

```{r}
set.ZeroPolicyOption(TRUE)

ngaWp_rswmQB <- nb2listw(wm_q, style = "B", zero.policy = TRUE)
ngaWp_rswmQB
```

```{r}
set.ZeroPolicyOption(TRUE)

ngaWp_rswmQC <- nb2listw(wm_q, style = "C", zero.policy = TRUE)
ngaWp_rswmQC
```

Regardless of which input for the style, all have the same result of 1 region without links while the average number of links is 5.736434.

#### 3.6.2.2 GSA : Moran's I method

Use the code chunk below.

Note :

*moran.test( )* to calculates the Moran's I Index value and both a a z-score and p-value to evaluate the significance of that Index.

*moran.mc( )* to do a permutation test to evaluate the rank of the observed statistic in relation to the statistic of simulated values.

```{r}
moran.test(nga_wp$wpt_nonFunctional, listw = ngaWp_rswmQW, zero.policy = TRUE, na.action = na.omit)
```

```{r}
set.seed(1234)
bperm_m = moran.mc(nga_wp$wpt_nonFunctional,
                 listw = ngaWp_rswmQW,
                 nsim = 999,
                 zero.policy = TRUE,
                 na.action = na.omit)
bperm_m
```

Remarks :

-   The value for both actual and random Moran's I almost the same, i.e. 0.43393, which means the non-functional water points are positively autocorrelated with the data spatially cluster.

-   There is a statistical significant with p-value (2.2e-16) \< 0.001, smaller than the alpha value to support the rejection of null hypothesis for the test i.e. the non-functional water points are not randomly spatial.

#### \-- visualise Monte Carlo Moran's I

Use the code chunk below.

Note :

*hist( )* to examine the simulated Moran's I test statistics by plotting the distribution of the statistical values as a histogram.

```{r}
hist(bperm_m$res, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I")
abline(v=0, 
       col="red") 
```

#### 3.6.2.3 GSA : Geary's C method

```{r}
geary.test(nga_wp$wpt_nonFunctional, listw=ngaWp_rswmQW)
```

```{r}
set.seed(1234)
bperm_c = geary.mc(nga_wp$wpt_nonFunctional,
               listw = ngaWp_rswmQW, 
               nsim = 999)
bperm_c
```

Remarks :

-   The value for both actual and random Geary's C almost the same, i.e. 0.61709, which means the non-functional water points are positively autocorrelated with the data spatially cluster.

-   There is a statistical significant with p-value (2.2e-16) \< 0.001, smaller than the alpha value to support the rejection of null hypothesis for the test i.e. the non-functional water points are not randomly spatial.

-   The Geary's C value is greater than the Moran's I value. However, since both values are less than 1, the observations tend to be clustered and similar.

<br>

### 3.7 Cluster and Outlier Analysis

Use Local Indicators for Spatial Association (LISA) method, especially local Moran's I to detect cluster and / or outlier.

#### 3.7.1 Compute Local Moran's I

Use the code chunk below.

```{r}
fips <- order(nga_wp$shapeName)
localMI <- localmoran(nga_wp$wpt_nonFunctional, ngaWp_rswmQW)
head(localMI)
```

#### 3.7.1.1 list the local Moran matrix derived

Use the code chunk below.

```{r}
printCoefmat(data.frame(localMI[fips,], nga_wp$shapeName[fips]), check.names=FALSE)
```

#### \-- append local Moran's I dataframe

Append local Moran's I dataframe (i.e.localMI) before mapping the local Moran's I map.

```{r}
nga_wp.localMI <- cbind(nga_wp,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

#### 3.7.1.2 plot local Moran's I values

```{r}
tm_shape(nga_wp.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

#### 3.7.1.3 plot local Moran's I p-value

```{r}
tm_shape(nga_wp.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "Local Moran's I p-value") +
  tm_borders(alpha = 0.5)
```

```{r}
localMI.map <- tm_shape(nga_wp.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)  +
  tm_layout(legend.height = 0.3, legend.width = 0.3)


pvalue.map <- tm_shape(nga_wp.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5) +
  tm_layout(legend.height = 0.26, legend.width = 0.3)

tmap_arrange(localMI.map, pvalue.map, asp=1.5, ncol=1)
```

### 3.8 Creating LISA Cluster Map

Plot the Moran scatterplot before generate the LISA cluster map.

#### 3.8.1 Plot Moran Scatterplot

Use the code chunk below.

The Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.

```{r}
nci <- moran.plot(nga_wp$wpt_nonFunctional, ngaWp_rswmQW,
                  labels=as.character(nga_wp$shapeName), 
                  xlab="Non-Functional Water Points", 
                  ylab="Spatially Lag wpt_nonFunctional")
```

#### 3.8.1.1 plot Moran Scatterplot with Standardised Variable

```{r}
nga_wp$z.wpt_nonFunctional <- scale(nga_wp$wpt_nonFunctional) %>% as.vector 
```

#### 3.8.1.2 plot Moran Scatterplot

```{r}
nci2 <- moran.plot(nga_wp$z.wpt_nonFunctional, ngaWp_rswmQW,
                   labels=as.character(nga_wp$shapeName),
                   xlab="z-wpt_nonFunctional", 
                   ylab="Spatially Lag z-wpt_nonFunctional")
```

#### 3.8.2 Prepare LISA Map Classes

Use code chunk below.

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
DV <- nga_wp$wpt_nonFunctional - mean(nga_wp$wpt_nonFunctional)    
C_mI <- localMI[,1] - mean(localMI[,1])    
signif <- 0.05       
quadrant[DV >0 & C_mI>0] <- 4      
quadrant[DV <0 & C_mI<0] <- 1      
quadrant[DV <0 & C_mI>0] <- 2
quadrant[DV >0 & C_mI<0] <- 3
quadrant[localMI[,5]>signif] <- 0
```

#### 3.8.3 Plot LISA Map

```{r}
nga_wp.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(nga_wp.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

```{r}
wpt_nonFunctional <- qtm(nga_wp, "wpt_nonFunctional") +
  tm_layout(legend.height = 0.28, legend.width = 0.25)

nga_wp.localMI$quadrant <- quadrant 
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high") 

LISAmap <- tm_shape(nga_wp.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5) +
  tm_layout(legend.height = 0.35, legend.width = 0.3)

tmap_arrange(wpt_nonFunctional, LISAmap, asp=1.5, ncol=1)
```

<br>

### 3.9 Hot Spot and Cold Spot Area Analysis

#### 3.9.1 Analyse with Getis and Ord's G-Statistics

```{r}

k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
upper_threshold <- max(unlist(nbdists(k1, coords, longlat = TRUE)))
```

```{r}
#| eval: false
wm_d39 <- dnearneigh(coords, 0, upper_threshold, longlat = TRUE)
wm_d39
```

```{r}
#| eval: false
wm39_lw <- nb2listw(wm_d39, style = 'B')
summary(wm39_lw)
```

```{r}
#| eval: false
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

```{r}
#| eval: false
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

#### 3.9.2 Compute Gi Statistics Using Fixed Distance

```{r}
#| eval: false
fips <- order(nga_wp$shapeName)
gi.fixed <- localG(nga_wp$wpt_nonFunctional, wm39_lw)
gi.fixed
```

```{r}
#| eval: false
nga_wp.gi <- cbind(nga_wp, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

```{r}
#| eval: false
wpt_nonFunctional <- qtm(nga_wp, "wpt_nonFunctional") +
  tm_layout(legend.height = 0.28, legend.width = 0.25)

Gimap <-tm_shape(nga_wp.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5) +
  tm_layout(legend.height = 0.28, legend.width = 0.25)

tmap_arrange(nga_wp, Gimap, asp=1.5, ncol=1)
```

#### 3.9.3 Compute Gi Statistics Using Adaptive Distance

```{r}
#| eval: false
fips <- order(nga_wp$shapeName)
gi.adaptive <- localG(nga_wp$wpt_nonFunctional, knn_lw)
nga_wp.gi <- cbind(nga_wp, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

```{r}
#| eval: false
wpt_nonFunctional <- qtm(nga_wp, "wpt_nonFunctional") +
  tm_layout(legend.height = 0.28, legend.width = 0.25)

Gimap <- tm_shape(nga_wp.gi) + 
  tm_fill(col = "gstat_adaptive", 
          style = "pretty", 
          palette="-RdBu", 
          title = "local Gi") + 
  tm_borders(alpha = 0.5) + 
  tm_layout(legend.height = 0.28, legend.width = 0.25)

tmap_arrange(wpt_nonFunctional,Gimap,asp=1.5,ncol=1)
```
